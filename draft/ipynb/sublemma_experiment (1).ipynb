{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip utils.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade transformers\n",
    "!pip install tqdm sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "import os\n",
    "folder_path = 'sublemma_proofs_miniF2F' # set this to where you want the proofs saved\n",
    "# Create the folder if it doesn't exist\n",
    "if not os.path.exists(folder_path):\n",
    "    os.makedirs(folder_path)\n",
    "    print(f\"Folder '{folder_path}' created successfully.\")\n",
    "else:\n",
    "    print(f\"Folder '{folder_path}' already exists.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: Install elan (Lean toolchain manager)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl https://raw.githubusercontent.com/leanprover/elan/master/elan-init.sh -sSf | sh -s -- -y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: Update Python process PATH so subprocess.run() can find `lean`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "elan_bin_path = os.path.expanduser(\"~/.elan/bin\")\n",
    "os.environ[\"PATH\"] = elan_bin_path + \":\" + os.environ[\"PATH\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify the installation by checking the version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!lean --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_lean_project(project_dir=\"/tmp/lean_project\"):\n",
    "    \"\"\"\n",
    "    Creates a Lean project, configures it to use Mathlib,\n",
    "    and downloads pre-compiled library files.\n",
    "    \"\"\"\n",
    "    print(f\"--- Setting up Lean project in: {project_dir} ---\")\n",
    "    os.makedirs(project_dir, exist_ok=True)\n",
    "\n",
    "    # Content for the lakefile.lean\n",
    "    lakefile_content = \"\"\"\n",
    "    import Lake\n",
    "    open Lake DSL\n",
    "    package «lean_project»\n",
    "    require mathlib from git\n",
    "      \"https://github.com/leanprover-community/mathlib4.git\"\n",
    "    @[default_target]\n",
    "    lean_lib «lean_project»\n",
    "    \"\"\"\n",
    "    # Write the lakefile\n",
    "    with open(os.path.join(project_dir, \"lakefile.lean\"), \"w\") as f:\n",
    "        f.write(lakefile_content)\n",
    "\n",
    "    # Run `lake exe cache get` to download Mathlib's pre-compiled files\n",
    "    # This is much faster than building from source.\n",
    "    print(\"--- Downloading Mathlib cache (this may take a few minutes)... ---\")\n",
    "    try:\n",
    "        subprocess.run(\n",
    "            [\"lake\", \"exe\", \"cache\", \"get\"],\n",
    "            cwd=project_dir,\n",
    "            check=True,\n",
    "            capture_output=True,\n",
    "            text=True\n",
    "        )\n",
    "        print(\"--- Mathlib cache downloaded successfully. ---\")\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(\"❌ Error setting up Mathlib cache.\")\n",
    "        print(f\"--- STDOUT ---\\n{e.stdout}\")\n",
    "        print(f\"--- STDERR ---\\n{e.stderr}\")\n",
    "        raise  # Stop execution if setup fails\n",
    "    return project_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- Call this function once at the start of your script ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lean_project_path = setup_lean_project()\n",
    "lean_project_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "print(utils.get_proof_variants)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import os\n",
    "import re\n",
    "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
    "from utils import get_proof_variants\n",
    "# from typing import Dict\n",
    "import threading\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOG_PATH = os.path.expanduser(\"~/error.log\")   # expand ~ -> /home/you/...\n",
    "os.makedirs(os.path.dirname(LOG_PATH) or \".\", exist_ok=True)\n",
    "_log_lock = threading.Lock()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_lean_proof(proof_and_context: dict, log_errors=True) -> bool:\n",
    "    \"\"\"\n",
    "    Checks a Lean‑4 proof string inside the given project using `lake`.\n",
    "    If any variant succeeds, the *first* successful proof is saved to:\n",
    "        corrected_proofs/<problem_id>/<proof_solver>/<attempt_id>.txt\n",
    "    Returns True if a proof was saved, otherwise False.\n",
    "    \"\"\"\n",
    "    # Verify the top‑level keys that must be present\n",
    "    assert \"proof\" in proof_and_context, \\\n",
    "        \"Missing 'proof' key – you need a proof string to test.\"\n",
    "    assert \"formal_statement\" in proof_and_context, \\\n",
    "        \"Missing 'formal_statement' key – you have to give the theorem statement.\"\n",
    "    assert \"project_dir\" in proof_and_context, \\\n",
    "        \"Missing 'project_dir' key – cannot locate the Lean project.\"\n",
    "    assert \"metadata\" in proof_and_context, \\\n",
    "        \"Missing 'metadata' key – you’ll need context such as attempt_id.\"\n",
    "\n",
    "    # Verify the required nested keys inside metadata\n",
    "    assert \"attempt_id\" in proof_and_context[\"metadata\"], \\\n",
    "        \"Metadata lacks 'attempt_id' – needed to name the output file.\"\n",
    "    assert \"problem_id\" in proof_and_context[\"metadata\"], \\\n",
    "        \"Metadata lacks 'problem_id' – needed for the directory structure.\"\n",
    "    assert \"proof_solver\" in proof_and_context[\"metadata\"], \\\n",
    "        \"Metadata lacks 'proof_solver' – you need to know which solver produced this.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Unpack everything we need\n",
    "    proof_string   = proof_and_context[\"proof\"]\n",
    "    statement      = proof_and_context[\"formal_statement\"]\n",
    "    project_dir    = proof_and_context[\"project_dir\"]\n",
    "    metadata       = proof_and_context[\"metadata\"]\n",
    "    attempt_id     = metadata[\"attempt_id\"]\n",
    "    problem_id     = metadata[\"problem_id\"]\n",
    "    solver_name    = metadata[\"proof_solver\"]\n",
    "    sanitized_solver = solver_name.replace(\"/\", \"_\").replace(\"\\\\\", \"_\")\n",
    "\n",
    "    # os.makedirs(project_dir, exist_ok=True)\n",
    "    # assert project_dir exists\n",
    "    assert os.path.exists(project_dir), \\\n",
    "        f\"Project directory '{project_dir}' does not exist.\"\n",
    "    print(\"I am here so assert passed\")\n",
    "\n",
    "    # Where the successful proof will be written.\n",
    "    save_dir = os.path.join(\n",
    "        Path(folder_path), \"corrected_proofs\", problem_id, sanitized_solver\n",
    "    )\n",
    "    os.makedirs(save_dir, exist_ok=True)          # make sure it exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Build every candidate proof.\n",
    "    proof_variants = get_proof_variants(proof_string)\n",
    "\n",
    "    # Each variant becomes a tiny Lean file: statement + proof.\n",
    "    candidates = [\n",
    "        f\"{statement}\\n{variant}\" for variant in proof_variants\n",
    "    ]\n",
    "\n",
    "    # Try them one by one.\n",
    "    for idx, code in enumerate(candidates):\n",
    "        temp_filename = f\"{problem_id}_{sanitized_solver}_{attempt_id}_{idx}.lean\"\n",
    "        temp_path = os.path.join(project_dir, temp_filename)\n",
    "        try:\n",
    "            print(temp_path)\n",
    "            # Write the candidate to a temporary file inside the project.\n",
    "            with open(temp_path, \"w\", encoding=\"utf-8\") as f:\n",
    "                f.write(code)\n",
    "\n",
    "            # Run Lean via lake.\n",
    "            desired = 100_000\n",
    "            command = [\n",
    "                \"lake\", \"env\", \"lean\",\n",
    "                f\"-DmaxRecDepth={desired}\",\n",
    "                temp_filename\n",
    "            ]\n",
    "            result = subprocess.run(\n",
    "                command,\n",
    "                cwd=project_dir,\n",
    "                capture_output=True,\n",
    "                text=True,\n",
    "                timeout=120,               # 2 minutes, just in case\n",
    "            )\n",
    "\n",
    "            # Success = returncode 0 and no “error:” in stdout.\n",
    "            if result.returncode == 0 and \"error:\" not in result.stdout:\n",
    "                # Save the *first* working proof.\n",
    "                out_path = os.path.join(save_dir, f\"{attempt_id}.txt\")\n",
    "                with open(out_path, \"w\", encoding=\"utf-8\") as out_f:\n",
    "                    out_f.write(proof_variants[idx])\n",
    "                # Clean up the temp file.\n",
    "                os.remove(temp_path)\n",
    "                print(f\"{solver_name} successfully proves {problem_id} on attempt: {attempt_id} ✅\")\n",
    "                return True   # yay, we found a good one\n",
    "            if log_errors:\n",
    "                if \"error:\" in result.stdout:\n",
    "                    # print(attempt_id, result.stdout)\n",
    "                    # thread-safe append\n",
    "                    with _log_lock:\n",
    "                        with open(LOG_PATH, \"a\", encoding=\"utf-8\") as g:\n",
    "                            g.writelines(result.stdout)\n",
    "\n",
    "            # If it failed, just treat this variant as “false” and move on.\n",
    "        except Exception as e:   # any crash = false for this variant\n",
    "            # minimal logging: type and message, plus any subprocess output we have\n",
    "            print(f\"Exception ({type(e).__name__}): {e}\")\n",
    "            proc = locals().get(\"result\")\n",
    "            if proc is not None:\n",
    "                print(\"---- subprocess stdout ----\")\n",
    "                print(proc.stdout or \"<no stdout>\")\n",
    "                print(\"---- subprocess stderr ----\")\n",
    "                print(proc.stderr or \"<no stderr>\")\n",
    "            # continue to next candidate\n",
    "        finally:\n",
    "            # Make sure we don’t leave stray temp files lying around.\n",
    "            if os.path.exists(temp_path):\n",
    "                try:\n",
    "                    os.remove(temp_path)\n",
    "                except Exception:\n",
    "                    pass\n",
    "\n",
    "    # No variant succeeded.\n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example of using check_lean_proof<br>\n",
    "correct_proof_dict = {<br>\n",
    "    'formal_statement': 'import Mathlib.Tactic\\ntheorem two_plus_two_is_four : 2 + 2 = 4',<br>\n",
    "    'proof': ':= by rfl',<br>\n",
    "    'project_dir': lean_project_path,<br>\n",
    "    'metadata': {'proof_solver': 'example_solver', 'problem_id': 'example_id', 'attempt_id': '1'}<br>\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check_lean_proof(correct_proof_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_formal_statement(formal_statement: str) -> tuple[str, str]:\n",
    "    \"\"\"\n",
    "    Splits a formal statement into header and lemma parts.\n",
    "    Args:\n",
    "        formal_statement: A string containing import statements, opens, and a lemma/theorem\n",
    "    Returns:\n",
    "        A tuple of (header, lemma) where:\n",
    "        - header contains all import and open statements\n",
    "        - lemma contains the lemma/theorem declaration and its signature\n",
    "    \"\"\"\n",
    "    lines = formal_statement.strip().split('\\n')\n",
    "\n",
    "    # Find the first line that starts with 'lemma', 'theorem', 'def', or 'example'\n",
    "    lemma_start_idx = 0\n",
    "    for i, line in enumerate(lines):\n",
    "        stripped = line.strip()\n",
    "        if stripped.startswith(('lemma ')):\n",
    "            lemma_start_idx = i\n",
    "            break\n",
    "\n",
    "    # Split into header and lemma\n",
    "    header_lines = lines[:lemma_start_idx]\n",
    "    lemma_lines = lines[lemma_start_idx:]\n",
    "\n",
    "    # Join back into strings\n",
    "    header = '\\n'.join(header_lines).strip()\n",
    "    lemma = '\\n'.join(lemma_lines).strip()\n",
    "    return header, lemma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "formal_statement = \n",
    "import Mathlib<br>\n",
    "open Real Nat Topology Complex<br>\n",
    "open scoped BigOperators<br>\n",
    "lemma h_cos_add (m n : ℝ) (k : ℕ) (a : ℕ → ℝ) (y : ℝ → ℝ) (h0 : 0 < k)<br>\n",
    "(h1 : ∀ x, y x = ∑ i ∈ Finset.range k, (Real.cos (a i + x)) / (2^i))<br>\n",
    "2 : y m = 0) (h3 : y n = 0) : ∀ i x, Real.cos (a i + x) = Real.cos (a i) * Real.cos x - Real.sin (a i) * Real.sin x := by\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "header, lemma = split_formal_statement(formal_statement)\n",
    "print(\"Header:\")\n",
    "print(header)\n",
    "print(\"\\nLemma:\")\n",
    "print(lemma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline, AutoConfig, AutoTokenizer, AutoModelForCausalLM\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _load_model(model_id):\n",
    "    \"\"\"\n",
    "    Loads a single model and tokenizer to the GPU, with a fix for rope_scaling issues.\n",
    "    \"\"\"\n",
    "    print(f\"Attempting to load model: {model_id}\")\n",
    "    try:\n",
    "        # 1. Load configuration first\n",
    "        config = AutoConfig.from_pretrained(model_id, trust_remote_code=True)\n",
    "\n",
    "        # 3. Load model and tokenizer with the (potentially corrected) config\n",
    "        tok = AutoTokenizer.from_pretrained(model_id, trust_remote_code=True)\n",
    "        model = AutoModelForCausalLM.from_pretrained(\n",
    "            model_id,\n",
    "            config=config, # Pass the corrected config\n",
    "            torch_dtype=\"auto\",\n",
    "            trust_remote_code=True\n",
    "        ).to(\"cuda\")\n",
    "        print(f\"Successfully loaded {model_id}\")\n",
    "        return model, tok\n",
    "    except Exception as e:\n",
    "        # Provide a more informative error message\n",
    "        logging.error(f\"❌ Failed to load model '{model_id}'. Error: {e}\")\n",
    "        # Return None to be handled by the calling function, preventing the crash\n",
    "        return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_proof(proof_cache, pipe, formal_statement,\n",
    "                   temperature: float = 0.5, max_new_tokens: int = 4096,\n",
    "                   num_return_sequences: int = 1):\n",
    "    def generate_prompt() -> str:\n",
    "        prompt = \"-- Below are some previously proved lemmas that might help:\\n\"\n",
    "        for lemma in proof_cache:\n",
    "            prompt += f\"{lemma}\\n\"\n",
    "        prompt += \"-- Now, using the above lemmas if needed, provide a proof for the following statement:\\n\"\n",
    "        prompt += f\"{formal_statement}\\n\"\n",
    "        return prompt\n",
    "    prompt = generate_prompt()\n",
    "\n",
    "    # Prepare arguments for the pipeline\n",
    "    generation_args = {\n",
    "        'do_sample': True,\n",
    "        'eos_token_id': pipe.tokenizer.eos_token_id,\n",
    "        'num_return_sequences': num_return_sequences,\n",
    "    }\n",
    "\n",
    "    # Only add max_new_tokens if a value is provided\n",
    "    # If it remains None, the pipeline will use its own default\n",
    "    if max_new_tokens is not None:\n",
    "        generation_args['max_new_tokens'] = max_new_tokens\n",
    "\n",
    "    # Call the pipeline with the arguments\n",
    "    out = pipe(prompt, **generation_args)\n",
    "    proofs = [result['generated_text'][len(prompt):].strip() for result in out]\n",
    "    return proofs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _sanitize_dir_name(name: str) -> str:\n",
    "    return str(name).replace(\"/\", \"_\").replace(\"\\\\\", \"_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _next_index(out_dir: Path) -> int:\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "    nums = []\n",
    "    for p in out_dir.glob(\"*.txt\"):\n",
    "        stem = p.stem\n",
    "        if stem.isdigit():\n",
    "            nums.append(int(stem))\n",
    "    return (max(nums) + 1) if nums else 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_proofs_memory_safe(\n",
    "    proof_cache,\n",
    "    model_ids,\n",
    "    problem_row,\n",
    "    problem_key,                 # e.g., DataFrame index or a unique ID column\n",
    "    max_attempts: int,\n",
    "    base_output_dir: str, # Added base_output_dir\n",
    "    gpu_batch_size: int = 8,\n",
    "    clear = True\n",
    "):\n",
    "    \"\"\"\n",
    "    Generate proofs and write to base_output_dir/<problem_key>/<model_id>/1.txt, 2.txt, ...\n",
    "    No proof checking; purely generation + IO. Memory-safe (loads one model at a time).\n",
    "    \"\"\"\n",
    "    for model_id in tqdm(model_ids, desc=\"Models\"):\n",
    "        model = tok = pipe = None\n",
    "        attempt_bar = None\n",
    "        try:\n",
    "            model, tok = _load_model(model_id)\n",
    "            pipe = pipeline(\"text-generation\", model=model, tokenizer=tok, device=0)\n",
    "            attempts_left = max_attempts\n",
    "            attempt_bar = tqdm(total=max_attempts, desc=f\"Generating {model_id}\", leave=False)\n",
    "\n",
    "            # Prepare output directory and next index (continues numbering if rerun)\n",
    "            out_dir = Path(base_output_dir) / _sanitize_dir_name(problem_key) / _sanitize_dir_name(model_id) # Modified out_dir\n",
    "            next_idx = _next_index(out_dir)\n",
    "            print(next_idx)\n",
    "\n",
    "            # raise Exception(\"Stop here\")\n",
    "            while attempts_left > 0:\n",
    "                current_batch_size = min(gpu_batch_size, attempts_left)\n",
    "                with torch.no_grad():\n",
    "                    proof_snippets = generate_proof(\n",
    "                        proof_cache,\n",
    "                        pipe,\n",
    "                        formal_statement=problem_row['formal_statement'],\n",
    "                        num_return_sequences=current_batch_size\n",
    "                    )\n",
    "                # Write each snippet to numbered files 1.txt, 2.txt, ...\n",
    "                for snippet in proof_snippets:\n",
    "                    out_path = out_dir / f\"{next_idx}.txt\"\n",
    "                    with open(out_path, \"w\", encoding=\"utf-8\") as f:\n",
    "                        f.write(snippet)\n",
    "                    next_idx += 1\n",
    "                attempts_left -= current_batch_size\n",
    "                attempt_bar.update(current_batch_size)\n",
    "        finally:\n",
    "          if clear:\n",
    "            if attempt_bar is not None:\n",
    "                attempt_bar.close()\n",
    "            if model: del model\n",
    "            if tok:   del tok\n",
    "            if pipe:  del pipe\n",
    "            gc.collect()\n",
    "            torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_proofs_for_model(\n",
    "    proof_cache,\n",
    "    model_id: str,\n",
    "    dataframe,\n",
    "    base_output_dir: str, # Added base_output_dir\n",
    "    max_attempts: int = 8,\n",
    "    gpu_batch_size: int = 8,\n",
    "    clear = True\n",
    "):\n",
    "    \"\"\"\n",
    "    For each problem in `dataframe`, generate `max_attempts` proofs for `model_id`\n",
    "    and write them to base_output_dir/<problem_key>/<model_id>/*.txt.\n",
    "    `problem_key` defaults to the DataFrame index value.\n",
    "    \"\"\"\n",
    "    print(f\"--- Generating proofs for model: {model_id} ---\")\n",
    "    for idx, problem_row in tqdm(dataframe.iterrows(), total=len(dataframe), desc=f\"Problems for {model_id}\"):\n",
    "        problem_key = problem_row.get('problem_id', idx)  # prefer a column named 'problem_id' if present\n",
    "        generate_proofs_memory_safe(\n",
    "            proof_cache,\n",
    "            model_ids=[model_id],\n",
    "            problem_row=problem_row,\n",
    "            problem_key=problem_key,\n",
    "            max_attempts=max_attempts,\n",
    "            base_output_dir=base_output_dir, # Passed base_output_dir\n",
    "            gpu_batch_size=gpu_batch_size,\n",
    "            clear = clear\n",
    "        )\n",
    "    print(f\"--- Done for {model_id}. ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proof_cache = [\"lemma h_cos_add (m n : ℝ) (k : ℕ) (a : ℕ → ℝ) (y : ℝ → ℝ) (h0 : 0 < k) (h1 : ∀ x, y x = ∑ i ∈ Finset.range k, (Real.cos (a i + x)) / (2^i)) (h2 : y m = 0) (h3 : y n = 0) : ∀ i x, Real.cos (a i + x) = Real.cos (a i) * Real.cos x - Real.sin (a i) * Real.sin x := by sorry\", \"lemma h_k_ge_one (m n : ℝ) (k : ℕ) (a : ℕ → ℝ) (y : ℝ → ℝ) (h0 : 0 < k) (h1 : ∀ x, y x = ∑ i ∈ Finset.range k, (Real.cos (a i + x)) / (2^i)) (h2 : y m = 0) (h3 : y n = 0) : 1 ≤ k := by sorry\"]\n",
    "solver_model_ids = [\n",
    "    \"Goedel-LM/Goedel-Prover-SFT\",\n",
    "    \"AI-MO/Kimina-Prover-Preview-Distill-7B\",\n",
    "    \"deepseek-ai/DeepSeek-Prover-V2-7B\",\n",
    "    # \"deepseek-ai/DeepSeek-Prover-V1.5-RL\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "# folder_path = \"\"\n",
    "# from google.colab import files\n",
    "# import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmas_df = load_dataset(\"script-jpg/imo-1969-p2-lemmas\", split=\"train\").to_pandas().iloc[16:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, mid in enumerate(solver_model_ids):\n",
    "    try:\n",
    "        write_proofs_for_model(proof_cache, mid, lemmas_df, base_output_dir=folder_path, max_attempts=8, gpu_batch_size=4, clear=False) # Passed folder_path\n",
    "     except Exception as e:\n",
    "         print(f\"Error for {mid}: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

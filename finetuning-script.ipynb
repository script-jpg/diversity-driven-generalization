{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":12799315,"sourceType":"datasetVersion","datasetId":8088098}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!uv pip install -q trl","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-19T23:11:24.682885Z","iopub.execute_input":"2025-08-19T23:11:24.683373Z","iopub.status.idle":"2025-08-19T23:11:44.374430Z","shell.execute_reply.started":"2025-08-19T23:11:24.683347Z","shell.execute_reply":"2025-08-19T23:11:44.373323Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import wandb\nwandb.login(key = \"WHAT?\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-19T23:53:04.090607Z","iopub.execute_input":"2025-08-19T23:53:04.090930Z","iopub.status.idle":"2025-08-19T23:53:09.800273Z","shell.execute_reply.started":"2025-08-19T23:53:04.090908Z","shell.execute_reply":"2025-08-19T23:53:09.799568Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from pathlib import Path\nimport pandas as pd\n\ndef load_proofs():\n    # Define the base directory where your 'Proofs' folder is located.\n    # Replace this with the actual path on your system.\n    base_path = Path('/kaggle/input/diversity')\n    \n    # Create a list to store the data from each file.\n    data_rows = []\n    \n    # Use glob to find all 'trial.txt' files within the structured directory.\n    # The '**' pattern means to search recursively in all subdirectories.\n    for file_path in base_path.glob('proofs/*/*/*.txt'):\n        \n        # The parts of the path are split by the OS-specific separator.\n        # We can access them by indexing from the end of the parts list.\n        path_parts = file_path.parts\n        \n        # The trial ID is the filename without the extension.\n        trial_id = file_path.stem\n        \n        # The model name is the directory one level up.\n        model = path_parts[-2]\n        \n        # The problem ID is the directory two levels up.\n        problem_id = path_parts[-3]\n        \n        # Read the content of the file.\n        try:\n            with file_path.open('r', encoding='utf-8') as f:\n                text_content = f.read()\n                \n            # Append a dictionary with the extracted data to our list.\n            data_rows.append({\n                'problem_id': problem_id,\n                'model': model,\n                'trial_id': trial_id,\n                'text': text_content\n            })\n        except Exception as e:\n            print(f\"Could not read file {file_path}: {e}\")\n    \n    # Create the pandas DataFrame from the list of dictionaries.\n    df = pd.DataFrame(data_rows)\n    return df","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-08-19T23:11:44.376272Z","iopub.execute_input":"2025-08-19T23:11:44.376586Z","iopub.status.idle":"2025-08-19T23:11:44.383515Z","shell.execute_reply.started":"2025-08-19T23:11:44.376563Z","shell.execute_reply":"2025-08-19T23:11:44.382406Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport json\nfrom datasets import load_dataset\n\ndef construct_dataset(model_name):\n    def format_dataset(elem):\n        informal_prefix = elem['informal_prefix']\n        formal_statement = elem['formal_statement']\n        idx = name2id[elem['name']]\n        trial_id = id2trial[idx]\n        #Find proof from dataframe\n        proof = df.loc[(df['problem_id'] == idx) & (df['trial_id'] == trial_id) & (df['model'] == model_name)]['text'].item()\n        prompt = f\"{informal_prefix}\\n\\n{formal_statement}\\n\\nproof\\n\"\n        return {\"prompt\": prompt, \"completion\": proof}\n    \n    #Proofs\n    df = load_proofs()\n    \n    #Get sucessful Trials\n    with open(\"/kaggle/input/diversity/proof_outcomes_by_model.json\", 'r') as file:\n        model2outcome = json.load(file)\n    id2trial = {}\n    for key, val in model2outcome[model_name].items():\n        try:\n            id2trial[key] = str(val.index(1) + 1)\n        except:\n            id2trial[key] = '1'\n    #Load minif2fdataset\n    raw_ds = load_dataset(\"AI-MO/minif2f_test\", split=\"train\")\n    raw_ds = raw_ds.select(range(40))\n    name2id = {name:str(i) for i, name in enumerate(raw_ds['name'])}\n    #PLEASE REMOVE id in the future\n    sft_ds = raw_ds.map(format_dataset, remove_columns =['name','informal_prefix', 'formal_statement'])\n    return sft_ds\n\nsft_ds = construct_dataset(\"stoney0062_Leanabell-Prover-DS-SFT\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-19T23:16:39.703313Z","iopub.execute_input":"2025-08-19T23:16:39.703706Z","iopub.status.idle":"2025-08-19T23:16:48.323762Z","shell.execute_reply.started":"2025-08-19T23:16:39.703684Z","shell.execute_reply":"2025-08-19T23:16:48.323020Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from transformers import (\n    AutoTokenizer,\n    AutoModelForCausalLM,\n    BitsAndBytesConfig,\n    TrainingArguments,\n    DataCollatorForLanguageModeling\n)\nimport torch\nfrom peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training\nfrom trl import SFTTrainer\n\nOUTPUT_DIR = \"./deepseek-prover-finetuned\"\nMODEL_ID = \"deepseek-ai/DeepSeek-Prover-V2-7B\"\n\n#Load Model\ntokenizer = AutoTokenizer.from_pretrained(MODEL_ID, trust_remote_code=True)\nmodel = AutoModelForCausalLM.from_pretrained(\n    MODEL_ID,\n    device_map=\"auto\",\n    trust_remote_code=True,\n    torch_dtype=torch.float16  \n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-19T23:13:49.664148Z","iopub.execute_input":"2025-08-19T23:13:49.664436Z","iopub.status.idle":"2025-08-19T23:16:11.277622Z","shell.execute_reply.started":"2025-08-19T23:13:49.664416Z","shell.execute_reply":"2025-08-19T23:16:11.277024Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"peft_config = LoraConfig(\n    r=16,\n    lora_alpha=32,\n    target_modules=[\"q_proj\", \"v_proj\"], # These are common for many models\n    lora_dropout=0.05,\n    bias=\"none\",\n    task_type=\"CAUSAL_LM\"\n)\ntraining_args = TrainingArguments(\n    output_dir=OUTPUT_DIR,\n    per_device_train_batch_size=4,\n    gradient_accumulation_steps=1,\n    learning_rate=2e-4,\n    num_train_epochs=3,\n    logging_steps=10,\n    save_strategy=\"epoch\",\n    max_grad_norm=0.3,\n    fp16=True,\n    max_steps=-1,\n    lr_scheduler_type=\"cosine\",\n    warmup_ratio=0.03,\n)\n\ntrainer = SFTTrainer(\n    model=model,\n    train_dataset=sft_ds,\n    peft_config=peft_config, # LoRA configuration\n    args = training_args\n)\n\ntrainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-19T23:16:56.393679Z","iopub.execute_input":"2025-08-19T23:16:56.394249Z","execution_failed":"2025-08-19T23:17:27.140Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"OUTPUT_DIR = \"./deepseek-prover-finetuned\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-19T18:22:24.999243Z","iopub.execute_input":"2025-08-19T18:22:25.000570Z","iopub.status.idle":"2025-08-19T18:22:25.006137Z","shell.execute_reply.started":"2025-08-19T18:22:25.000532Z","shell.execute_reply":"2025-08-19T18:22:25.004930Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# peft_config = LoraConfig(\n#     r=16,\n#     lora_alpha=32,\n#     target_modules=[\"q_proj\", \"v_proj\"], # These are common for many models\n#     lora_dropout=0.05,\n#     bias=\"none\",\n#     task_type=\"CAUSAL_LM\"\n# )\n\n# trainer = SFTTrainer(\n#     model=model,\n#     train_dataset=sft_ds,\n#     peft_config=peft_config,  # LoRA configuration\n# )\n\n\n\n# training_args = TrainingArguments(\n#     output_dir=OUTPUT_DIR,\n#     per_device_train_batch_size=4,\n#     gradient_accumulation_steps=1,\n#     learning_rate=2e-4,\n#     num_train_epochs=3,\n#     logging_steps=10,\n#     save_strategy=\"epoch\",\n#     max_grad_norm=0.3,\n#     max_steps=-1,\n#     lr_scheduler_type=\"cosine\",\n#     warmup_ratio=0.03,\n# )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-19T18:26:20.682202Z","iopub.execute_input":"2025-08-19T18:26:20.682582Z","iopub.status.idle":"2025-08-19T18:26:22.430322Z","shell.execute_reply.started":"2025-08-19T18:26:20.682561Z","shell.execute_reply":"2025-08-19T18:26:22.429065Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"trainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-19T18:26:25.105566Z","iopub.execute_input":"2025-08-19T18:26:25.105920Z","execution_failed":"2025-08-19T18:28:37.134Z"}},"outputs":[],"execution_count":null}]}
{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IHPx26WXsbG2"
      },
      "outputs": [],
      "source": [
        "!unzip utils.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hPnE8K2PrY0V",
        "outputId": "dedb1c57-b405-4833-a18d-0ea51e499956"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.35.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.10)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.10.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.12/dist-packages (0.2.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade transformers\n",
        "!pip install tqdm sentencepiece"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YpvRwiYerUP6",
        "outputId": "3da983ad-2550-4e06-a054-00f28773f483"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Folder '/content/drive/MyDrive/sublemma_proofs_miniF2F' already exists.\n"
          ]
        }
      ],
      "source": [
        "# Comment out this part if not using Google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "\n",
        "# Define the path to the new folder in Google Drive\n",
        "folder_path = '/content/drive/MyDrive/sublemma_proofs_miniF2F' # set this to where you want the proofs saved\n",
        "\n",
        "# Create the folder if it doesn't exist\n",
        "if not os.path.exists(folder_path):\n",
        "    os.makedirs(folder_path)\n",
        "    print(f\"Folder '{folder_path}' created successfully.\")\n",
        "else:\n",
        "    print(f\"Folder '{folder_path}' already exists.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "id": "h66kC-0trUP9",
        "outputId": "36135cd0-8646-4825-961f-76c9d8626169"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1minfo:\u001b[0m downloading installer\n",
            "\u001b[1minfo: \u001b[mdefault toolchain set to 'stable'\n",
            "Lean (version 4.24.0, x86_64-unknown-linux-gnu, commit 797c613eb9b6d4ec95db23e3e00af9ac6657f24b, Release)\n",
            "--- Setting up Lean project in: /tmp/lean_project ---\n",
            "--- Downloading Mathlib cache (this may take a few minutes)... ---\n",
            "--- Mathlib cache downloaded successfully. ---\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/tmp/lean_project'"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "# Step 1: Install elan (Lean toolchain manager)\n",
        "!curl https://raw.githubusercontent.com/leanprover/elan/master/elan-init.sh -sSf | sh -s -- -y\n",
        "\n",
        "# Step 2: Update Python process PATH so subprocess.run() can find `lean`\n",
        "import os\n",
        "elan_bin_path = os.path.expanduser(\"~/.elan/bin\")\n",
        "os.environ[\"PATH\"] = elan_bin_path + \":\" + os.environ[\"PATH\"]\n",
        "\n",
        "# Verify the installation by checking the version\n",
        "!lean --version\n",
        "\n",
        "import os\n",
        "import subprocess\n",
        "import json\n",
        "\n",
        "def setup_lean_project(project_dir=\"/tmp/lean_project\"):\n",
        "    \"\"\"\n",
        "    Creates a Lean project, configures it to use Mathlib,\n",
        "    and downloads pre-compiled library files.\n",
        "    \"\"\"\n",
        "    print(f\"--- Setting up Lean project in: {project_dir} ---\")\n",
        "    os.makedirs(project_dir, exist_ok=True)\n",
        "\n",
        "    # Content for the lakefile.lean\n",
        "    lakefile_content = \"\"\"\n",
        "    import Lake\n",
        "    open Lake DSL\n",
        "\n",
        "    package «lean_project»\n",
        "\n",
        "    require mathlib from git\n",
        "      \"https://github.com/leanprover-community/mathlib4.git\"\n",
        "\n",
        "    @[default_target]\n",
        "    lean_lib «lean_project»\n",
        "    \"\"\"\n",
        "    # Write the lakefile\n",
        "    with open(os.path.join(project_dir, \"lakefile.lean\"), \"w\") as f:\n",
        "        f.write(lakefile_content)\n",
        "\n",
        "    # Run `lake exe cache get` to download Mathlib's pre-compiled files\n",
        "    # This is much faster than building from source.\n",
        "    print(\"--- Downloading Mathlib cache (this may take a few minutes)... ---\")\n",
        "    try:\n",
        "        subprocess.run(\n",
        "            [\"lake\", \"exe\", \"cache\", \"get\"],\n",
        "            cwd=project_dir,\n",
        "            check=True,\n",
        "            capture_output=True,\n",
        "            text=True\n",
        "        )\n",
        "        print(\"--- Mathlib cache downloaded successfully. ---\")\n",
        "    except subprocess.CalledProcessError as e:\n",
        "        print(\"❌ Error setting up Mathlib cache.\")\n",
        "        print(f\"--- STDOUT ---\\n{e.stdout}\")\n",
        "        print(f\"--- STDERR ---\\n{e.stderr}\")\n",
        "        raise  # Stop execution if setup fails\n",
        "\n",
        "    return project_dir\n",
        "\n",
        "# --- Call this function once at the start of your script ---\n",
        "lean_project_path = setup_lean_project()\n",
        "lean_project_path\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S4bb_8JJrUP-",
        "outputId": "8bbaa240-a547-4126-b880-547fb18a331d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<function get_proof_variants at 0x7e695d01fc40>\n"
          ]
        }
      ],
      "source": [
        "import utils\n",
        "print(utils.get_proof_variants)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "iKHxTeykrUP_"
      },
      "outputs": [],
      "source": [
        "import subprocess\n",
        "import os\n",
        "import re\n",
        "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
        "from utils import get_proof_variants\n",
        "# from typing import Dict\n",
        "import threading\n",
        "from pathlib import Path\n",
        "\n",
        "LOG_PATH = os.path.expanduser(\"~/error.log\")   # expand ~ -> /home/you/...\n",
        "os.makedirs(os.path.dirname(LOG_PATH) or \".\", exist_ok=True)\n",
        "_log_lock = threading.Lock()\n",
        "\n",
        "def check_lean_proof(proof_and_context: dict, log_errors=True) -> bool:\n",
        "    \"\"\"\n",
        "    Checks a Lean‑4 proof string inside the given project using `lake`.\n",
        "    If any variant succeeds, the *first* successful proof is saved to:\n",
        "        corrected_proofs/<problem_id>/<proof_solver>/<attempt_id>.txt\n",
        "    Returns True if a proof was saved, otherwise False.\n",
        "    \"\"\"\n",
        "    # Verify the top‑level keys that must be present\n",
        "    assert \"proof\" in proof_and_context, \\\n",
        "        \"Missing 'proof' key – you need a proof string to test.\"\n",
        "    assert \"formal_statement\" in proof_and_context, \\\n",
        "        \"Missing 'formal_statement' key – you have to give the theorem statement.\"\n",
        "    assert \"project_dir\" in proof_and_context, \\\n",
        "        \"Missing 'project_dir' key – cannot locate the Lean project.\"\n",
        "    assert \"metadata\" in proof_and_context, \\\n",
        "        \"Missing 'metadata' key – you’ll need context such as attempt_id.\"\n",
        "\n",
        "    # Verify the required nested keys inside metadata\n",
        "    assert \"attempt_id\" in proof_and_context[\"metadata\"], \\\n",
        "        \"Metadata lacks 'attempt_id' – needed to name the output file.\"\n",
        "    assert \"problem_id\" in proof_and_context[\"metadata\"], \\\n",
        "        \"Metadata lacks 'problem_id' – needed for the directory structure.\"\n",
        "    assert \"proof_solver\" in proof_and_context[\"metadata\"], \\\n",
        "        \"Metadata lacks 'proof_solver' – you need to know which solver produced this.\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # Unpack everything we need\n",
        "    proof_string   = proof_and_context[\"proof\"]\n",
        "    statement      = proof_and_context[\"formal_statement\"]\n",
        "    project_dir    = proof_and_context[\"project_dir\"]\n",
        "\n",
        "    metadata       = proof_and_context[\"metadata\"]\n",
        "    attempt_id     = metadata[\"attempt_id\"]\n",
        "    problem_id     = metadata[\"problem_id\"]\n",
        "    solver_name    = metadata[\"proof_solver\"]\n",
        "\n",
        "    sanitized_solver = solver_name.replace(\"/\", \"_\").replace(\"\\\\\", \"_\")\n",
        "\n",
        "    # os.makedirs(project_dir, exist_ok=True)\n",
        "    # assert project_dir exists\n",
        "    assert os.path.exists(project_dir), \\\n",
        "        f\"Project directory '{project_dir}' does not exist.\"\n",
        "\n",
        "    print(\"I am here so assert passed\")\n",
        "\n",
        "    # Where the successful proof will be written.\n",
        "    save_dir = os.path.join(\n",
        "        Path(folder_path), \"corrected_proofs\", problem_id, solver_name\n",
        "    )\n",
        "    os.makedirs(save_dir, exist_ok=True)          # make sure it exists\n",
        "\n",
        "\n",
        "    # Build every candidate proof.\n",
        "    proof_variants = get_proof_variants(proof_string)\n",
        "\n",
        "    # Each variant becomes a tiny Lean file: statement + proof.\n",
        "    candidates = [\n",
        "        f\"{statement}\\n{variant}\" for variant in proof_variants\n",
        "    ]\n",
        "\n",
        "    # Try them one by one.\n",
        "    for idx, code in enumerate(candidates):\n",
        "        temp_filename = f\"{problem_id}_{sanitized_solver}_{attempt_id}_{idx}.lean\"\n",
        "        temp_path = os.path.join(project_dir, temp_filename)\n",
        "\n",
        "        try:\n",
        "            print(temp_path)\n",
        "            # Write the candidate to a temporary file inside the project.\n",
        "            with open(temp_path, \"w\", encoding=\"utf-8\") as f:\n",
        "                f.write(code)\n",
        "\n",
        "            # Run Lean via lake.\n",
        "            desired = 100_000\n",
        "            command = [\n",
        "                \"lake\", \"env\", \"lean\",\n",
        "                f\"-DmaxRecDepth={desired}\",\n",
        "                temp_filename\n",
        "            ]\n",
        "            result = subprocess.run(\n",
        "                command,\n",
        "                cwd=project_dir,\n",
        "                capture_output=True,\n",
        "                text=True,\n",
        "                timeout=120,               # 2 minutes, just in case\n",
        "            )\n",
        "\n",
        "            # Success = returncode 0 and no “error:” in stdout.\n",
        "            if result.returncode == 0 and \"error:\" not in result.stdout:\n",
        "                # Save the *first* working proof.\n",
        "                out_path = os.path.join(save_dir, f\"{attempt_id}.txt\")\n",
        "                with open(out_path, \"w\", encoding=\"utf-8\") as out_f:\n",
        "                    out_f.write(proof_variants[idx])\n",
        "\n",
        "                # Clean up the temp file.\n",
        "                os.remove(temp_path)\n",
        "\n",
        "                print(f\"{solver_name} successfully proves {problem_id} on attempt: {attempt_id} ✅\")\n",
        "\n",
        "                return True   # yay, we found a good one\n",
        "            if log_errors:\n",
        "                if \"error:\" in result.stdout:\n",
        "                    # print(attempt_id, result.stdout)\n",
        "                    # thread-safe append\n",
        "                    with _log_lock:\n",
        "                        with open(LOG_PATH, \"a\", encoding=\"utf-8\") as g:\n",
        "                            g.writelines(result.stdout)\n",
        "\n",
        "            # If it failed, just treat this variant as “false” and move on.\n",
        "        except Exception as e:   # any crash = false for this variant\n",
        "            # minimal logging: type and message, plus any subprocess output we have\n",
        "            print(f\"Exception ({type(e).__name__}): {e}\")\n",
        "            proc = locals().get(\"result\")\n",
        "            if proc is not None:\n",
        "                print(\"---- subprocess stdout ----\")\n",
        "                print(proc.stdout or \"<no stdout>\")\n",
        "                print(\"---- subprocess stderr ----\")\n",
        "                print(proc.stderr or \"<no stderr>\")\n",
        "            # continue to next candidate\n",
        "        finally:\n",
        "            # Make sure we don’t leave stray temp files lying around.\n",
        "            if os.path.exists(temp_path):\n",
        "                try:\n",
        "                    os.remove(temp_path)\n",
        "                except Exception:\n",
        "                    pass\n",
        "\n",
        "    # No variant succeeded.\n",
        "    return False\n",
        "\n",
        "# # Example of using check_lean_proof\n",
        "# correct_proof_dict = {\n",
        "#     'formal_statement': 'import Mathlib.Tactic\\ntheorem two_plus_two_is_four : 2 + 2 = 4',\n",
        "#     'proof': ':= by rfl',\n",
        "#     'project_dir': lean_project_path,\n",
        "#     'metadata': {'proof_solver': 'example_solver', 'problem_id': 'example_id', 'attempt_id': '1'}\n",
        "# }\n",
        "\n",
        "# check_lean_proof(correct_proof_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sW2QPMZnrUP_",
        "outputId": "937ca70d-65b6-466c-b05b-7eaf2b2962a1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Header:\n",
            "import Mathlib\n",
            "\n",
            "open Real Nat Topology Complex\n",
            "open scoped BigOperators\n",
            "\n",
            "Lemma:\n",
            "lemma h_cos_add (m n : ℝ) (k : ℕ) (a : ℕ → ℝ) (y : ℝ → ℝ) (h0 : 0 < k)\n",
            "(h1 : ∀ x, y x = ∑ i ∈ Finset.range k, (Real.cos (a i + x)) / (2^i))\n",
            "(h2 : y m = 0) (h3 : y n = 0) : ∀ i x, Real.cos (a i + x) = Real.cos (a i) * Real.cos x - Real.sin (a i) * Real.sin x := by\n"
          ]
        }
      ],
      "source": [
        "def split_formal_statement(formal_statement: str) -> tuple[str, str]:\n",
        "    \"\"\"\n",
        "    Splits a formal statement into header and lemma parts.\n",
        "\n",
        "    Args:\n",
        "        formal_statement: A string containing import statements, opens, and a lemma/theorem\n",
        "\n",
        "    Returns:\n",
        "        A tuple of (header, lemma) where:\n",
        "        - header contains all import and open statements\n",
        "        - lemma contains the lemma/theorem declaration and its signature\n",
        "    \"\"\"\n",
        "    lines = formal_statement.strip().split('\\n')\n",
        "\n",
        "    # Find the first line that starts with 'lemma', 'theorem', 'def', or 'example'\n",
        "    lemma_start_idx = 0\n",
        "    for i, line in enumerate(lines):\n",
        "        stripped = line.strip()\n",
        "        if stripped.startswith(('lemma ')):\n",
        "            lemma_start_idx = i\n",
        "            break\n",
        "\n",
        "    # Split into header and lemma\n",
        "    header_lines = lines[:lemma_start_idx]\n",
        "    lemma_lines = lines[lemma_start_idx:]\n",
        "\n",
        "    # Join back into strings\n",
        "    header = '\\n'.join(header_lines).strip()\n",
        "    lemma = '\\n'.join(lemma_lines).strip()\n",
        "\n",
        "    return header, lemma\n",
        "\n",
        "# Test the function\n",
        "formal_statement = \"\"\"import Mathlib\n",
        "\n",
        "open Real Nat Topology Complex\n",
        "open scoped BigOperators\n",
        "\n",
        "lemma h_cos_add (m n : ℝ) (k : ℕ) (a : ℕ → ℝ) (y : ℝ → ℝ) (h0 : 0 < k)\n",
        "(h1 : ∀ x, y x = ∑ i ∈ Finset.range k, (Real.cos (a i + x)) / (2^i))\n",
        "(h2 : y m = 0) (h3 : y n = 0) : ∀ i x, Real.cos (a i + x) = Real.cos (a i) * Real.cos x - Real.sin (a i) * Real.sin x := by\"\"\"\n",
        "\n",
        "header, lemma = split_formal_statement(formal_statement)\n",
        "print(\"Header:\")\n",
        "print(header)\n",
        "print(\"\\nLemma:\")\n",
        "print(lemma)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "OrZmg7OOrUQA"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline, AutoConfig, AutoTokenizer, AutoModelForCausalLM\n",
        "import logging\n",
        "\n",
        "def _load_model(model_id):\n",
        "    \"\"\"\n",
        "    Loads a single model and tokenizer to the GPU, with a fix for rope_scaling issues.\n",
        "    \"\"\"\n",
        "    print(f\"Attempting to load model: {model_id}\")\n",
        "    try:\n",
        "        # 1. Load configuration first\n",
        "        config = AutoConfig.from_pretrained(model_id, trust_remote_code=True)\n",
        "\n",
        "        # 3. Load model and tokenizer with the (potentially corrected) config\n",
        "        tok = AutoTokenizer.from_pretrained(model_id, trust_remote_code=True)\n",
        "        model = AutoModelForCausalLM.from_pretrained(\n",
        "            model_id,\n",
        "            config=config, # Pass the corrected config\n",
        "            torch_dtype=\"auto\",\n",
        "            trust_remote_code=True\n",
        "        ).to(\"cuda\")\n",
        "\n",
        "        print(f\"Successfully loaded {model_id}\")\n",
        "        return model, tok\n",
        "\n",
        "    except Exception as e:\n",
        "        # Provide a more informative error message\n",
        "        logging.error(f\"❌ Failed to load model '{model_id}'. Error: {e}\")\n",
        "        # Return None to be handled by the calling function, preventing the crash\n",
        "        return None, None\n",
        "\n",
        "def generate_proof(proof_cache, pipe, formal_statement,\n",
        "                   temperature: float = 0.5, max_new_tokens: int = 4096,\n",
        "                   num_return_sequences: int = 1):\n",
        "\n",
        "    def generate_prompt() -> str:\n",
        "        prompt = \"-- Below are some previously proved lemmas that might help:\\n\"\n",
        "        for lemma in proof_cache:\n",
        "            prompt += f\"{lemma}\\n\"\n",
        "        prompt += \"-- Now, using the above lemmas if needed, provide a proof for the following statement:\\n\"\n",
        "        prompt += f\"{formal_statement}\\n\"\n",
        "        return prompt\n",
        "\n",
        "    prompt = generate_prompt()\n",
        "\n",
        "    # Prepare arguments for the pipeline\n",
        "    generation_args = {\n",
        "        'do_sample': True,\n",
        "        'eos_token_id': pipe.tokenizer.eos_token_id,\n",
        "        'num_return_sequences': num_return_sequences,\n",
        "\n",
        "    }\n",
        "\n",
        "    # Only add max_new_tokens if a value is provided\n",
        "    # If it remains None, the pipeline will use its own default\n",
        "    if max_new_tokens is not None:\n",
        "        generation_args['max_new_tokens'] = max_new_tokens\n",
        "\n",
        "    # Call the pipeline with the arguments\n",
        "    out = pipe(prompt, **generation_args)\n",
        "\n",
        "    proofs = [result['generated_text'][len(prompt):].strip() for result in out]\n",
        "    return proofs\n",
        "\n",
        "import gc\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "from transformers import pipeline\n",
        "\n",
        "def _sanitize_dir_name(name: str) -> str:\n",
        "    return str(name).replace(\"/\", \"_\").replace(\"\\\\\", \"_\")\n",
        "\n",
        "def _next_index(out_dir: Path) -> int:\n",
        "    out_dir.mkdir(parents=True, exist_ok=True)\n",
        "    nums = []\n",
        "    for p in out_dir.glob(\"*.txt\"):\n",
        "        stem = p.stem\n",
        "        if stem.isdigit():\n",
        "            nums.append(int(stem))\n",
        "    return (max(nums) + 1) if nums else 1\n",
        "\n",
        "def generate_proofs_memory_safe(\n",
        "    proof_cache,\n",
        "    model_ids,\n",
        "    problem_row,\n",
        "    problem_key,                 # e.g., DataFrame index or a unique ID column\n",
        "    max_attempts: int,\n",
        "    base_output_dir: str, # Added base_output_dir\n",
        "    gpu_batch_size: int = 8,\n",
        "    clear = True\n",
        "):\n",
        "    \"\"\"\n",
        "    Generate proofs and write to base_output_dir/<problem_key>/<model_id>/1.txt, 2.txt, ...\n",
        "    No proof checking; purely generation + IO. Memory-safe (loads one model at a time).\n",
        "    \"\"\"\n",
        "    for model_id in tqdm(model_ids, desc=\"Models\"):\n",
        "        model = tok = pipe = None\n",
        "        attempt_bar = None\n",
        "        try:\n",
        "            model, tok = _load_model(model_id)\n",
        "            pipe = pipeline(\"text-generation\", model=model, tokenizer=tok, device=0)\n",
        "\n",
        "            attempts_left = max_attempts\n",
        "            attempt_bar = tqdm(total=max_attempts, desc=f\"Generating {model_id}\", leave=False)\n",
        "\n",
        "            # Prepare output directory and next index (continues numbering if rerun)\n",
        "            out_dir = Path(base_output_dir) / _sanitize_dir_name(problem_key) / _sanitize_dir_name(model_id) # Modified out_dir\n",
        "            next_idx = _next_index(out_dir)\n",
        "\n",
        "            print(next_idx)\n",
        "\n",
        "            # raise Exception(\"Stop here\")\n",
        "\n",
        "            while attempts_left > 0:\n",
        "                current_batch_size = min(gpu_batch_size, attempts_left)\n",
        "                with torch.no_grad():\n",
        "                    proof_snippets = generate_proof(\n",
        "                        proof_cache,\n",
        "                        pipe,\n",
        "                        formal_statement=problem_row['formal_statement'],\n",
        "                        num_return_sequences=current_batch_size\n",
        "                    )\n",
        "\n",
        "                # Write each snippet to numbered files 1.txt, 2.txt, ...\n",
        "                for snippet in proof_snippets:\n",
        "                    out_path = out_dir / f\"{next_idx}.txt\"\n",
        "                    with open(out_path, \"w\", encoding=\"utf-8\") as f:\n",
        "                        f.write(snippet)\n",
        "                    next_idx += 1\n",
        "\n",
        "                attempts_left -= current_batch_size\n",
        "                attempt_bar.update(current_batch_size)\n",
        "\n",
        "        finally:\n",
        "          if clear:\n",
        "            if attempt_bar is not None:\n",
        "                attempt_bar.close()\n",
        "            if model: del model\n",
        "            if tok:   del tok\n",
        "            if pipe:  del pipe\n",
        "            gc.collect()\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "def write_proofs_for_model(\n",
        "    proof_cache,\n",
        "    model_id: str,\n",
        "    dataframe,\n",
        "    base_output_dir: str, # Added base_output_dir\n",
        "    max_attempts: int = 8,\n",
        "    gpu_batch_size: int = 8,\n",
        "    clear = True\n",
        "):\n",
        "    \"\"\"\n",
        "    For each problem in `dataframe`, generate `max_attempts` proofs for `model_id`\n",
        "    and write them to base_output_dir/<problem_key>/<model_id>/*.txt.\n",
        "    `problem_key` defaults to the DataFrame index value.\n",
        "    \"\"\"\n",
        "    print(f\"--- Generating proofs for model: {model_id} ---\")\n",
        "    for idx, problem_row in tqdm(dataframe.iterrows(), total=len(dataframe), desc=f\"Problems for {model_id}\"):\n",
        "        problem_key = problem_row.get('problem_id', idx)  # prefer a column named 'problem_id' if present\n",
        "        generate_proofs_memory_safe(\n",
        "            proof_cache,\n",
        "            model_ids=[model_id],\n",
        "            problem_row=problem_row,\n",
        "            problem_key=problem_key,\n",
        "            max_attempts=max_attempts,\n",
        "            base_output_dir=base_output_dir, # Passed base_output_dir\n",
        "            gpu_batch_size=gpu_batch_size,\n",
        "            clear = clear\n",
        "        )\n",
        "    print(f\"--- Done for {model_id}. ---\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "fb42905925814d2499a2ae3966448edd",
            "15ac72fc80f24e4b84cb4bde2ade60ea",
            "3db938a611ed4914b5b48e00842dfef6",
            "9ffd732f2f4d49e88b75fdf88d436740",
            "445cbbeeb7f54ed88db840da7b14a82b",
            "6fa2b1efdd01480e85587eef4d45590a",
            "48d19894cc1f4b5b94179b2a4010158e",
            "4da6b8f775024cafba253dc55420fbc8",
            "43da809bde0a4a2b96d7d7ad549732da",
            "00070ee47edf47cea179c0ab6fa69daa",
            "7a8ed9e0614d4df998a5835bbdf2c0f2"
          ]
        },
        "id": "2IUsPECerUQB",
        "outputId": "97eed189-cea1-48ed-8c0d-f196af10f73b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Checking proofs for model: Goedel-LM/Goedel-Prover-SFT ---\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Problems for Goedel-LM/Goedel-Prover-SFT:   0%|          | 0/23 [00:00<?, ?it/s]\n",
            "Models:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Attempting to load model: Goedel-LM/Goedel-Prover-SFT\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`torch_dtype` is deprecated! Use `dtype` instead!\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fb42905925814d2499a2ae3966448edd",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Successfully loaded Goedel-LM/Goedel-Prover-SFT\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Generating Goedel-LM/Goedel-Prover-SFT:   0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\u001b[A"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Generating Goedel-LM/Goedel-Prover-SFT:  50%|█████     | 4/8 [00:41<00:41, 10.50s/it]\u001b[A\u001b[A\n",
            "\n",
            "Generating Goedel-LM/Goedel-Prover-SFT: 100%|██████████| 8/8 [01:07<00:00,  8.04s/it]\u001b[A\u001b[A\n",
            "Models: 100%|██████████| 1/1 [01:13<00:00, 73.04s/it]\n",
            "\n",
            "\n",
            "                                                                                     \u001b[A\u001b[A"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/sublemma_proofs_miniF2F/1/Goedel-LM_Goedel-Prover-SFT\n",
            "<generator object Path.glob at 0x7e67a90b3230>\n",
            "{'formal_statement': 'import Mathlib\\n\\nopen Real Nat Topology Complex\\nopen scoped BigOperators\\n\\nlemma h_y_sum_expanded (m n : ℝ) (k : ℕ) (a : ℕ → ℝ) (y : ℝ → ℝ) (h0 : 0 < k) \\n    (h1 : ∀ x, y x = ∑ i ∈ Finset.range k, (Real.cos (a i + x)) / (2^i)) \\n    (h2 : y m = 0) (h3 : y n = 0) : ∀ x : ℝ, y x = ∑ i ∈ Finset.range k, (Real.cos (a i) * Real.cos x - Real.sin (a i) * Real.sin x) / (2^i) := by', 'proof': '/-\\n  We need to show that for any real number \\\\( x \\\\), the function \\\\( y(x) \\\\) can be expressed as the sum of terms involving trigonometric functions. Given the definitions and properties of the trigonometric functions, we can directly substitute and simplify to verify the equality.\\n  -/\\n  -- Introduce an arbitrary real number x to prove the equality for all x.\\n  intro x\\n  -- Simplify the expression using the given definitions and properties of trigonometric functions.\\n  simp_all [Finset.sum_range_succ, Real.cos_add, Real.sin_add, mul_add, mul_sub, mul_one, mul_div_cancel_left]\\n```', 'project_dir': '/tmp/lean_project', 'metadata': {'proof_solver': 'Goedel-LM/Goedel-Prover-SFT', 'problem_id': '1', 'attempt_id': '1'}}\n",
            "I am here so assert passed\n",
            "/tmp/lean_project/1_Goedel-LM_Goedel-Prover-SFT_1_0.lean\n",
            "/tmp/lean_project/1_Goedel-LM_Goedel-Prover-SFT_1_1.lean\n",
            "/tmp/lean_project/1_Goedel-LM_Goedel-Prover-SFT_1_2.lean\n",
            "Goedel-LM/Goedel-Prover-SFT successfully proves 1 on attempt: 1 ✅\n",
            "{'formal_statement': 'import Mathlib\\n\\nopen Real Nat Topology Complex\\nopen scoped BigOperators\\n\\nlemma h_y_sum_expanded (m n : ℝ) (k : ℕ) (a : ℕ → ℝ) (y : ℝ → ℝ) (h0 : 0 < k) \\n    (h1 : ∀ x, y x = ∑ i ∈ Finset.range k, (Real.cos (a i + x)) / (2^i)) \\n    (h2 : y m = 0) (h3 : y n = 0) : ∀ x : ℝ, y x = ∑ i ∈ Finset.range k, (Real.cos (a i) * Real.cos x - Real.sin (a i) * Real.sin x) / (2^i) := by', 'proof': 'intro x\\n  -- Use the given lemma `h_cos_add` to expand the cosine function in the sum.\\n  simp only [h1, h2, h3]\\n  -- Apply the lemma `h_cos_add` to each term in the sum.\\n  simp [Finset.sum_range_succ, h_cos_add]\\n```', 'project_dir': '/tmp/lean_project', 'metadata': {'proof_solver': 'Goedel-LM/Goedel-Prover-SFT', 'problem_id': '1', 'attempt_id': '2'}}\n",
            "I am here so assert passed\n",
            "/tmp/lean_project/1_Goedel-LM_Goedel-Prover-SFT_2_0.lean\n",
            "/tmp/lean_project/1_Goedel-LM_Goedel-Prover-SFT_2_1.lean\n",
            "/tmp/lean_project/1_Goedel-LM_Goedel-Prover-SFT_2_2.lean\n",
            "/tmp/lean_project/1_Goedel-LM_Goedel-Prover-SFT_2_3.lean\n",
            "/tmp/lean_project/1_Goedel-LM_Goedel-Prover-SFT_2_4.lean\n",
            "{'formal_statement': 'import Mathlib\\n\\nopen Real Nat Topology Complex\\nopen scoped BigOperators\\n\\nlemma h_y_sum_expanded (m n : ℝ) (k : ℕ) (a : ℕ → ℝ) (y : ℝ → ℝ) (h0 : 0 < k) \\n    (h1 : ∀ x, y x = ∑ i ∈ Finset.range k, (Real.cos (a i + x)) / (2^i)) \\n    (h2 : y m = 0) (h3 : y n = 0) : ∀ x : ℝ, y x = ∑ i ∈ Finset.range k, (Real.cos (a i) * Real.cos x - Real.sin (a i) * Real.sin x) / (2^i) := by', 'proof': '/-\\n  We need to show that for any real number \\\\( x \\\\), the function \\\\( y(x) \\\\) can be expressed as the sum of terms involving the cosine and sine of \\\\( a_i \\\\) and \\\\( x \\\\), divided by \\\\( 2^i \\\\). Given the definitions and properties of the cosine and sine functions, we can directly substitute and simplify to achieve this.\\n  -/\\n  intro x\\n  -- Substitute the definition of y from h1 into the goal\\n  rw [h1]\\n  -- Simplify the expression using the properties of cosine and sine\\n  simp [h0, h1, h2, h3, Real.cos_add, Real.sin_add, mul_add, mul_comm, mul_left_comm]\\n  -- Use the ring tactic to simplify the algebraic expression\\n  <;> ring\\n```', 'project_dir': '/tmp/lean_project', 'metadata': {'proof_solver': 'Goedel-LM/Goedel-Prover-SFT', 'problem_id': '1', 'attempt_id': '3'}}\n",
            "I am here so assert passed\n",
            "/tmp/lean_project/1_Goedel-LM_Goedel-Prover-SFT_3_0.lean\n",
            "/tmp/lean_project/1_Goedel-LM_Goedel-Prover-SFT_3_1.lean\n",
            "/tmp/lean_project/1_Goedel-LM_Goedel-Prover-SFT_3_2.lean\n",
            "Goedel-LM/Goedel-Prover-SFT successfully proves 1 on attempt: 3 ✅\n",
            "{'formal_statement': 'import Mathlib\\n\\nopen Real Nat Topology Complex\\nopen scoped BigOperators\\n\\nlemma h_y_sum_expanded (m n : ℝ) (k : ℕ) (a : ℕ → ℝ) (y : ℝ → ℝ) (h0 : 0 < k) \\n    (h1 : ∀ x, y x = ∑ i ∈ Finset.range k, (Real.cos (a i + x)) / (2^i)) \\n    (h2 : y m = 0) (h3 : y n = 0) : ∀ x : ℝ, y x = ∑ i ∈ Finset.range k, (Real.cos (a i) * Real.cos x - Real.sin (a i) * Real.sin x) / (2^i) := by', 'proof': '/-\\n  Given the function \\\\( y(x) = \\\\sum_{i=0}^{k-1} \\\\frac{\\\\cos(a_i + x)}{2^i} \\\\) where \\\\( a_i \\\\) is a real number and \\\\( a_i = 0 \\\\) for all \\\\( i \\\\), we need to show that \\\\( y(x) = \\\\sum_{i=0}^{k-1} \\\\frac{\\\\cos(a_i + x)}{2^i} \\\\).\\n  1. Start by substituting \\\\( a_i = 0 \\\\) into the expression for \\\\( y(x) \\\\).\\n  2. Simplify the expression using the properties of the cosine function and the fact that \\\\( \\\\cos(a_i + x) = \\\\cos(0 + x) = \\\\cos(x) \\\\).\\n  3. Recognize that the sum of the series simplifies to a constant value due to the properties of the cosine function and the geometric series.\\n  -/\\n  intro x\\n  -- Substitute \\\\( a_i = 0 \\\\) into the expression for \\\\( y(x) \\\\)\\n  simp_all [Finset.sum_range_succ, h0]\\n  -- Simplify the expression using the properties of the cosine function and the geometric series\\n  <;> simp_all [Real.cos_zero]\\n  -- Recognize that the sum of the series simplifies to a constant value due to the properties of the cosine function and the geometric series\\n  <;> simp_all [h1, h2, h3]\\n  <;> simp_all [Finset.sum_range_succ, h0]\\n  <;> simp_all [Real.cos_zero]\\n  <;> simp_all [h1, h2, h3]\\n  <;> simp_all [Finset.sum_range_succ, h0]\\n  <;> simp_all [Real.cos_zero]\\n  <;> simp_all [h1, h2, h3]\\n  <;> simp_all [Finset.sum_range_succ, h0]\\n  <;> simp_all [Real.cos_zero]\\n  <;> simp_all [h1, h2, h3]\\n  <;> simp_all [Finset.sum_range_succ, h0]\\n  <;> simp_all [Real.cos_zero]\\n  <;> simp_all [h1, h2, h3]\\n```', 'project_dir': '/tmp/lean_project', 'metadata': {'proof_solver': 'Goedel-LM/Goedel-Prover-SFT', 'problem_id': '1', 'attempt_id': '4'}}\n",
            "I am here so assert passed\n",
            "/tmp/lean_project/1_Goedel-LM_Goedel-Prover-SFT_4_0.lean\n",
            "/tmp/lean_project/1_Goedel-LM_Goedel-Prover-SFT_4_1.lean\n",
            "/tmp/lean_project/1_Goedel-LM_Goedel-Prover-SFT_4_2.lean\n",
            "/tmp/lean_project/1_Goedel-LM_Goedel-Prover-SFT_4_3.lean\n",
            "/tmp/lean_project/1_Goedel-LM_Goedel-Prover-SFT_4_4.lean\n",
            "{'formal_statement': 'import Mathlib\\n\\nopen Real Nat Topology Complex\\nopen scoped BigOperators\\n\\nlemma h_y_sum_expanded (m n : ℝ) (k : ℕ) (a : ℕ → ℝ) (y : ℝ → ℝ) (h0 : 0 < k) \\n    (h1 : ∀ x, y x = ∑ i ∈ Finset.range k, (Real.cos (a i + x)) / (2^i)) \\n    (h2 : y m = 0) (h3 : y n = 0) : ∀ x : ℝ, y x = ∑ i ∈ Finset.range k, (Real.cos (a i) * Real.cos x - Real.sin (a i) * Real.sin x) / (2^i) := by', 'proof': '/-\\n  The theorem states that for any real number \\\\( x \\\\), the function \\\\( y \\\\) defined as \\\\( y(x) = \\\\sum_{i=0}^{k-1} \\\\frac{\\\\cos(a_i + x)}{2^i} \\\\) can be expressed as \\\\( y(x) = \\\\sum_{i=0}^{k-1} \\\\frac{\\\\cos(a_i) \\\\cos(x) - \\\\sin(a_i) \\\\sin(x)}{2^i} \\\\). This is achieved by using the trigonometric identity for the cosine of a sum, specifically \\\\( \\\\cos(a_i + x) = \\\\cos(a_i) \\\\cos(x) - \\\\sin(a_i) \\\\sin(x) \\\\).\\n  -/\\n  intro x\\n  -- Use the given definition of y and the trigonometric identity for cos(a_i + x)\\n  simp [h1, h2, h3, Real.cos_add]\\n  -- Simplify the expression using the identity and properties of sums and powers\\n  <;> simp_all [Finset.sum_range_succ, Finset.sum_range_succ, Finset.sum_range_succ, Finset.sum_range_succ]\\n  -- Normalize the expression to achieve the final form\\n  <;> ring_nf\\n  -- Simplify using the given hypotheses\\n  <;> simp_all [h0, h1, h2, h3]\\n  -- Finalize the simplification\\n  <;> ring_nf\\n```', 'project_dir': '/tmp/lean_project', 'metadata': {'proof_solver': 'Goedel-LM/Goedel-Prover-SFT', 'problem_id': '1', 'attempt_id': '5'}}\n",
            "I am here so assert passed\n",
            "/tmp/lean_project/1_Goedel-LM_Goedel-Prover-SFT_5_0.lean\n",
            "/tmp/lean_project/1_Goedel-LM_Goedel-Prover-SFT_5_1.lean\n",
            "/tmp/lean_project/1_Goedel-LM_Goedel-Prover-SFT_5_2.lean\n",
            "Goedel-LM/Goedel-Prover-SFT successfully proves 1 on attempt: 5 ✅\n",
            "{'formal_statement': 'import Mathlib\\n\\nopen Real Nat Topology Complex\\nopen scoped BigOperators\\n\\nlemma h_y_sum_expanded (m n : ℝ) (k : ℕ) (a : ℕ → ℝ) (y : ℝ → ℝ) (h0 : 0 < k) \\n    (h1 : ∀ x, y x = ∑ i ∈ Finset.range k, (Real.cos (a i + x)) / (2^i)) \\n    (h2 : y m = 0) (h3 : y n = 0) : ∀ x : ℝ, y x = ∑ i ∈ Finset.range k, (Real.cos (a i) * Real.cos x - Real.sin (a i) * Real.sin x) / (2^i) := by', 'proof': '/-\\n  Given a sequence of positive real numbers \\\\( a_1, a_2, \\\\ldots, a_k \\\\) and a real number \\\\( \\\\lambda \\\\), we define the polynomial \\\\( P_k(x) \\\\) as:\\n  \\\\[ P_k(x) = \\\\sum_{i=1}^k \\\\frac{\\\\cos(a_i + x)}{2^i} \\\\]\\n  We need to prove that if \\\\( y_m = 0 \\\\) and \\\\( y_n = 0 \\\\) for some real numbers \\\\( m \\\\) and \\\\( n \\\\), then:\\n  \\\\[ \\\\cos(a_i + x) = \\\\cos(a_i) \\\\cos(x) - \\\\sin(a_i) \\\\sin(x) \\\\]\\n  for all \\\\( i \\\\) and \\\\( x \\\\).\\n  -/\\n  intro x\\n  -- Using the given definitions and properties, we can directly apply the provided lemma h_cos_add.\\n  simpa [h1] using h_cos_add m n k a y h0 h1 h2 h3 x\\n```', 'project_dir': '/tmp/lean_project', 'metadata': {'proof_solver': 'Goedel-LM/Goedel-Prover-SFT', 'problem_id': '1', 'attempt_id': '6'}}\n",
            "I am here so assert passed\n",
            "/tmp/lean_project/1_Goedel-LM_Goedel-Prover-SFT_6_0.lean\n"
          ]
        }
      ],
      "source": [
        "proof_cache = [\"lemma h_cos_add (m n : ℝ) (k : ℕ) (a : ℕ → ℝ) (y : ℝ → ℝ) (h0 : 0 < k)(h1 : ∀ x, y x = ∑ i ∈ Finset.range k, (Real.cos (a i + x)) / (2^i))(h2 : y m = 0) (h3 : y n = 0) : ∀ i x, Real.cos (a i + x) = Real.cos (a i) * Real.cos x - Real.sin (a i) * Real.sin x := by sorry\"]\n",
        "solver_model_ids = [\n",
        "    \"Goedel-LM/Goedel-Prover-SFT\",\n",
        "    # \"AI-MO/Kimina-Prover-Preview-Distill-7B\",\n",
        "    # \"deepseek-ai/DeepSeek-Prover-V2-7B\",\n",
        "    # \"deepseek-ai/DeepSeek-Prover-V1.5-RL\"\n",
        "]\n",
        "\n",
        "from datasets import load_dataset\n",
        "# folder_path = \"\"\n",
        "# from google.colab import files\n",
        "# import time\n",
        "\n",
        "lemmas_df = load_dataset(\"script-jpg/imo-1969-p2-lemmas\", split=\"train\").to_pandas()\n",
        "\n",
        "for i, mid in enumerate(solver_model_ids):\n",
        "    try:\n",
        "      # write_proofs_for_model(proof_cache, mid, lemmas_df, base_output_dir=folder_path, max_attempts=8, gpu_batch_size=4, clear=False) # Passed folder_path\n",
        "      # After generating proofs, check them and update proof_cache\n",
        "      print(f\"--- Checking proofs for model: {mid} ---\")\n",
        "      for idx, problem_row in tqdm(lemmas_df.iloc[1:].iterrows(), total=len(lemmas_df)-1, desc=f\"Problems for {mid}\"):\n",
        "          problem_key = problem_row.get('problem_id', idx)  # prefer a column named 'problem_id' if present\n",
        "          generate_proofs_memory_safe(\n",
        "              proof_cache,\n",
        "              model_ids=[mid],\n",
        "              problem_row=problem_row,\n",
        "              problem_key=problem_key,\n",
        "              max_attempts=8,\n",
        "              base_output_dir=folder_path, # Passed base_output_dir\n",
        "              gpu_batch_size=4,\n",
        "              clear = False\n",
        "          )\n",
        "\n",
        "      # for idx, problem_row in tqdm(lemmas_df.iterrows(), total=len(lemmas_df), desc=f\"Checking proofs for {mid}\"):\n",
        "\n",
        "          problem_solved_once = False\n",
        "          problem_key = problem_row.get('problem_id', idx)\n",
        "          model_dir = Path(folder_path) / _sanitize_dir_name(problem_key) / _sanitize_dir_name(mid)\n",
        "\n",
        "          print(model_dir)\n",
        "          print(model_dir.glob(\"*.txt\"))\n",
        "          # Check all generated proof files for this problem and model\n",
        "          for proof_file in model_dir.glob(\"*.txt\"):\n",
        "              with open(proof_file, \"r\", encoding=\"utf-8\") as f:\n",
        "                  proof_content = f.read().strip()\n",
        "\n",
        "              # Construct correct_proof_dict\n",
        "              correct_proof_dict = {\n",
        "                  'formal_statement': problem_row['formal_statement'],\n",
        "                  'proof': proof_content,\n",
        "                  'project_dir': lean_project_path,\n",
        "                  'metadata': {\n",
        "                      'proof_solver': mid,\n",
        "                      'problem_id': str(problem_key),\n",
        "                      'attempt_id': proof_file.stem\n",
        "                  }\n",
        "              }\n",
        "\n",
        "              print(correct_proof_dict)\n",
        "\n",
        "              # Check proof and update proof_cache if successful\n",
        "              is_correct = check_lean_proof(correct_proof_dict, log_errors=True)\n",
        "\n",
        "              problem_solved_once = problem_solved_once or is_correct\n",
        "\n",
        "              # Write to a log file in nested format\n",
        "              log_file_path = Path(folder_path) / \"proof_checking_log.json\"\n",
        "              log_file_path.parent.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "              # Read existing log or create new structure\n",
        "              if log_file_path.exists():\n",
        "                  with open(log_file_path, \"r\", encoding=\"utf-8\") as f:\n",
        "                      try:\n",
        "                          log_data = json.load(f)\n",
        "                      except json.JSONDecodeError:\n",
        "                          log_data = {}\n",
        "              else:\n",
        "                  log_data = {}\n",
        "\n",
        "              # Initialize nested structure if needed\n",
        "              problem_key_str = str(problem_key)\n",
        "              if problem_key_str not in log_data:\n",
        "                  log_data[problem_key_str] = {}\n",
        "\n",
        "              # Sanitize model name for JSON key\n",
        "              model_key = _sanitize_dir_name(mid)\n",
        "              if model_key not in log_data[problem_key_str]:\n",
        "                  log_data[problem_key_str][model_key] = []\n",
        "\n",
        "              # Append the result (1 for correct, 0 for incorrect)\n",
        "              log_data[problem_key_str][model_key].append(1 if is_correct else 0)\n",
        "\n",
        "              # Write back to file\n",
        "              with open(log_file_path, \"w\", encoding=\"utf-8\") as f:\n",
        "                  json.dump(log_data, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "          if problem_solved_once:\n",
        "              formal_statement = problem_row['formal_statement']\n",
        "              proved_lemma = split_formal_statement(formal_statement)[1] + \" sorry\" # proved by `sorry`\n",
        "              proof_cache.append(proved_lemma)\n",
        "\n",
        "      print(f\"--- Proof cache size after checking {mid}: {len(proof_cache)} ---\")\n",
        "\n",
        "    except Exception as e:\n",
        "      print(f\"Error for {mid}: {e}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "00070ee47edf47cea179c0ab6fa69daa": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "15ac72fc80f24e4b84cb4bde2ade60ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6fa2b1efdd01480e85587eef4d45590a",
            "placeholder": "​",
            "style": "IPY_MODEL_48d19894cc1f4b5b94179b2a4010158e",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "3db938a611ed4914b5b48e00842dfef6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4da6b8f775024cafba253dc55420fbc8",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_43da809bde0a4a2b96d7d7ad549732da",
            "value": 3
          }
        },
        "43da809bde0a4a2b96d7d7ad549732da": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "445cbbeeb7f54ed88db840da7b14a82b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "48d19894cc1f4b5b94179b2a4010158e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4da6b8f775024cafba253dc55420fbc8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6fa2b1efdd01480e85587eef4d45590a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7a8ed9e0614d4df998a5835bbdf2c0f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9ffd732f2f4d49e88b75fdf88d436740": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_00070ee47edf47cea179c0ab6fa69daa",
            "placeholder": "​",
            "style": "IPY_MODEL_7a8ed9e0614d4df998a5835bbdf2c0f2",
            "value": " 3/3 [00:00&lt;00:00, 50.37it/s]"
          }
        },
        "fb42905925814d2499a2ae3966448edd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_15ac72fc80f24e4b84cb4bde2ade60ea",
              "IPY_MODEL_3db938a611ed4914b5b48e00842dfef6",
              "IPY_MODEL_9ffd732f2f4d49e88b75fdf88d436740"
            ],
            "layout": "IPY_MODEL_445cbbeeb7f54ed88db840da7b14a82b"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
